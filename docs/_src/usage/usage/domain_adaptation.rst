Domain Adaptation
=================

In our experience, language models trained on squad show very strong general question answering capabilities
Though LMs trained usually on large web corpora, and though squad is wiki, these models are flexible enough to deal with many different doc styles
You don't always need to know what a HP Valve is to answer what is connected to a HP Valve, the answer might be there in plain language

If you do want to perform domain adaptation, this is possible within FARM
Labelling tool to create question answering pairs (!! link !!)
export
train reader model

Can other components be retrained?

